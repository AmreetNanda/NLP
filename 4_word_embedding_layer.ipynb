{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12db6922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e3a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\n",
    "    'The glass of milk',\n",
    "    'The glass of juice',\n",
    "    'The cup of tea',\n",
    "    'I am a good person',\n",
    "    'I am a good developer',\n",
    "    'Understanding the meaning of words',\n",
    "    'The videos are good'\n",
    "]\n",
    "voc_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e77bf7",
   "metadata": {},
   "source": [
    "#### One_Hot_Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617d91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431, 476, 189, 417], [431, 476, 189, 452], [431, 244, 189, 202], [132, 242, 173, 96, 323], [132, 242, 173, 96, 65], [478, 431, 364, 189, 475], [431, 206, 355, 96]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr = [one_hot(word, voc_size) for word in sentence]\n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102cd86",
   "metadata": {},
   "source": [
    "#### Word embedding representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db6f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6e436",
   "metadata": {},
   "source": [
    "#### Pre-Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f91e85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0 431 476 189 417]\n",
      " [  0   0   0   0 431 476 189 452]\n",
      " [  0   0   0   0 431 244 189 202]\n",
      " [  0   0   0 132 242 173  96 323]\n",
      " [  0   0   0 132 242 173  96  65]\n",
      " [  0   0   0 478 431 364 189 475]\n",
      " [  0   0   0   0 431 206 355  96]]\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 8\n",
    "embedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sentence_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b4bbe",
   "metadata": {},
   "source": [
    "#### Setting a 10 feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0151387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amreet\\Desktop\\NLP\\NLP\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [ 0.00205506,  0.00716865, -0.01395572, -0.03380241,\n",
       "         -0.02619652, -0.03840851,  0.00606748,  0.01569916,\n",
       "         -0.0491646 ,  0.02691598],\n",
       "        [-0.03386682, -0.04751248, -0.03497412,  0.01173105,\n",
       "         -0.02636142, -0.01017267,  0.00980538, -0.01770563,\n",
       "         -0.04999174, -0.01692646],\n",
       "        [ 0.00275468, -0.01471126, -0.01514991,  0.02976987,\n",
       "          0.01650852,  0.04950931,  0.03554164, -0.02992183,\n",
       "         -0.03488634, -0.00047425],\n",
       "        [ 0.03481459, -0.00559412, -0.03027145,  0.01352844,\n",
       "          0.04731809,  0.00457726, -0.00083858, -0.02854371,\n",
       "         -0.03393626, -0.03550779]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [ 0.00205506,  0.00716865, -0.01395572, -0.03380241,\n",
       "         -0.02619652, -0.03840851,  0.00606748,  0.01569916,\n",
       "         -0.0491646 ,  0.02691598],\n",
       "        [-0.03386682, -0.04751248, -0.03497412,  0.01173105,\n",
       "         -0.02636142, -0.01017267,  0.00980538, -0.01770563,\n",
       "         -0.04999174, -0.01692646],\n",
       "        [ 0.00275468, -0.01471126, -0.01514991,  0.02976987,\n",
       "          0.01650852,  0.04950931,  0.03554164, -0.02992183,\n",
       "         -0.03488634, -0.00047425],\n",
       "        [ 0.03227748, -0.01965716,  0.02192244,  0.02532272,\n",
       "          0.03872751, -0.01265953,  0.03759103,  0.04604422,\n",
       "         -0.0334697 ,  0.03373399]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [ 0.00205506,  0.00716865, -0.01395572, -0.03380241,\n",
       "         -0.02619652, -0.03840851,  0.00606748,  0.01569916,\n",
       "         -0.0491646 ,  0.02691598],\n",
       "        [ 0.03261007, -0.04792032,  0.03937617,  0.02995614,\n",
       "          0.01345308, -0.03256128,  0.00593128,  0.04989609,\n",
       "         -0.00012023, -0.03519415],\n",
       "        [ 0.00275468, -0.01471126, -0.01514991,  0.02976987,\n",
       "          0.01650852,  0.04950931,  0.03554164, -0.02992183,\n",
       "         -0.03488634, -0.00047425],\n",
       "        [-0.03711881,  0.03739972, -0.03879917, -0.0131854 ,\n",
       "          0.03878666,  0.03813139,  0.01028543,  0.03775607,\n",
       "          0.01099615,  0.03312801]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.03224454,  0.02261144, -0.0412887 ,  0.01493898,\n",
       "         -0.02215537,  0.00856458,  0.03682238,  0.01880019,\n",
       "         -0.02526548, -0.0429685 ],\n",
       "        [ 0.0348362 ,  0.02557175,  0.00947209,  0.00148548,\n",
       "         -0.0229331 , -0.04833972, -0.00540785, -0.01624703,\n",
       "         -0.03203874,  0.03378122],\n",
       "        [ 0.03166525, -0.02055998, -0.04807537,  0.03669706,\n",
       "          0.0305219 ,  0.00300393, -0.03561036, -0.04844737,\n",
       "          0.0098187 ,  0.03348072],\n",
       "        [-0.01645247,  0.02943733,  0.03318217, -0.01384133,\n",
       "          0.00746835, -0.02224424, -0.03165817, -0.03612161,\n",
       "          0.00946886,  0.0283442 ],\n",
       "        [ 0.00064114, -0.01536084, -0.00034714, -0.04609947,\n",
       "          0.01018291,  0.03526962, -0.04699655, -0.04805558,\n",
       "         -0.03555112, -0.01507252]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.03224454,  0.02261144, -0.0412887 ,  0.01493898,\n",
       "         -0.02215537,  0.00856458,  0.03682238,  0.01880019,\n",
       "         -0.02526548, -0.0429685 ],\n",
       "        [ 0.0348362 ,  0.02557175,  0.00947209,  0.00148548,\n",
       "         -0.0229331 , -0.04833972, -0.00540785, -0.01624703,\n",
       "         -0.03203874,  0.03378122],\n",
       "        [ 0.03166525, -0.02055998, -0.04807537,  0.03669706,\n",
       "          0.0305219 ,  0.00300393, -0.03561036, -0.04844737,\n",
       "          0.0098187 ,  0.03348072],\n",
       "        [-0.01645247,  0.02943733,  0.03318217, -0.01384133,\n",
       "          0.00746835, -0.02224424, -0.03165817, -0.03612161,\n",
       "          0.00946886,  0.0283442 ],\n",
       "        [ 0.01160489,  0.00662911,  0.00598636, -0.01136627,\n",
       "          0.03240991, -0.04162662,  0.00861255, -0.00026107,\n",
       "         -0.01767033, -0.02365738]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [ 0.00386838, -0.04350754,  0.04339239,  0.01565574,\n",
       "         -0.00499632,  0.00631051, -0.03181554, -0.001581  ,\n",
       "          0.0367117 , -0.02449453],\n",
       "        [ 0.00205506,  0.00716865, -0.01395572, -0.03380241,\n",
       "         -0.02619652, -0.03840851,  0.00606748,  0.01569916,\n",
       "         -0.0491646 ,  0.02691598],\n",
       "        [-0.00319983, -0.0410145 ,  0.02433774, -0.02529467,\n",
       "          0.04034753,  0.00124459,  0.04605336, -0.04334363,\n",
       "         -0.04974625,  0.04543198],\n",
       "        [ 0.00275468, -0.01471126, -0.01514991,  0.02976987,\n",
       "          0.01650852,  0.04950931,  0.03554164, -0.02992183,\n",
       "         -0.03488634, -0.00047425],\n",
       "        [ 0.04453896, -0.04624082, -0.0370701 ,  0.04239161,\n",
       "         -0.02691013, -0.01162683,  0.01480278, -0.01650807,\n",
       "          0.03974367,  0.00140659]],\n",
       "\n",
       "       [[-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [-0.01301723, -0.00108662, -0.04132137,  0.02309126,\n",
       "          0.02578744,  0.04249266, -0.04090729,  0.00450731,\n",
       "         -0.03793967,  0.03573665],\n",
       "        [ 0.00205506,  0.00716865, -0.01395572, -0.03380241,\n",
       "         -0.02619652, -0.03840851,  0.00606748,  0.01569916,\n",
       "         -0.0491646 ,  0.02691598],\n",
       "        [ 0.03156299, -0.00613094,  0.00568016, -0.0256192 ,\n",
       "          0.00708117,  0.0462775 , -0.00767392, -0.02244719,\n",
       "         -0.04933148, -0.01348957],\n",
       "        [-0.04468397,  0.01739873, -0.04192303,  0.03668961,\n",
       "          0.02567636, -0.01637527,  0.02852723, -0.0021201 ,\n",
       "          0.04810399, -0.01840027],\n",
       "        [-0.01645247,  0.02943733,  0.03318217, -0.01384133,\n",
       "          0.00746835, -0.02224424, -0.03165817, -0.03612161,\n",
       "          0.00946886,  0.0283442 ]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, dim, input_length=sentence_length))\n",
    "model.compile('adam','rse')\n",
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542141b0",
   "metadata": {},
   "source": [
    "## Another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0115b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8333e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "064887d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48, 11], [22, 11], [17, 5], [38, 11], [47], [19], [21, 5], [4, 22], [21, 11], [25, 3, 11, 23]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0c7432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431 476 189 417]\n",
      " [431 476 189 452]\n",
      " [431 244 189 202]\n",
      " [242 173  96 323]\n",
      " [242 173  96  65]\n",
      " [431 364 189 475]\n",
      " [431 206 355  96]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(onehot_repr, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c96aabc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "# print(model.summary())\n",
    "\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2674d6",
   "metadata": {},
   "source": [
    "For more ref : [How to use word embedding layers](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
